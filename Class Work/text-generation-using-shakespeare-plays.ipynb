{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5905f192afbe87792d896dd14681d17d3a0e3d56"
   },
   "source": [
    "# Text Generation using LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "512cd60c810dd603d17be067807b411a08ee559d"
   },
   "source": [
    "## 1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras module for building LSTM \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "# set seeds for reproducability\n",
    "from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "set_random_seed(2)\n",
    "seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f97e0f257c2dc189b005ae8644f091462a0f2e1"
   },
   "source": [
    "## 2. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4d73cfb9b02bd0d71c4f34c7b993f1e0ef18e310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111396\n"
     ]
    }
   ],
   "source": [
    "curr_dir = '../input/'\n",
    "play_df = pd.read_csv(curr_dir + 'Shakespeare_data.csv')\n",
    "\n",
    "all_lines = [h for h in play_df.PlayerLine]\n",
    "\n",
    "print(len(all_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4c7666282d868bfff2ad4e0003a08d1647469ba"
   },
   "source": [
    "## 3. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d6860d63866dac238af6ac322cfca9dfbfc450a"
   },
   "source": [
    "First, we will clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0fffe13f0aadc2086a0f0eb850a61b52ea23d44b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act i',\n",
       " 'scene i london the palace',\n",
       " 'enter king henry lord john of lancaster the earl of westmoreland sir walter blunt and others',\n",
       " 'so shaken as we are so wan with care',\n",
       " 'find we a time for frighted peace to pant',\n",
       " 'and breathe shortwinded accents of new broils',\n",
       " 'to be commenced in strands afar remote',\n",
       " 'no more the thirsty entrance of this soil',\n",
       " 'shall daub her lips with her own childrens blood',\n",
       " 'nor more shall trenching war channel her fields']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "\n",
    "corpus = [clean_text(x) for x in all_lines]\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4bad9be83e45bf6d81ebfe8228a35ddb190e8b83"
   },
   "source": [
    "Next we will generate sequence of N-gram tokens using Keras' Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8914e8ba72af09af3cec0af43f10cee7a5c420d8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[523, 4],\n",
       " [142, 4],\n",
       " [142, 4, 339],\n",
       " [142, 4, 339, 1],\n",
       " [142, 4, 339, 1, 670],\n",
       " [53, 41],\n",
       " [53, 41, 84],\n",
       " [53, 41, 84, 29],\n",
       " [53, 41, 84, 29, 124],\n",
       " [53, 41, 84, 29, 124, 3]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    corpus = corpus[:7000]\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "inp_sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "994ff08a7cc3e7272e478a71c8cd9a4402f6078f"
   },
   "source": [
    "Next we will generate padded sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45584, 33), (45584, 6543))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
    "predictors.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ef8b7889b835026d57d8fc4cf0aece8d4856f0e"
   },
   "source": [
    "## 4. Using LSTM for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b4645207118a3c61ba400310ae74157ed371a806",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 33, 10)            65430     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               1071104   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6543)              3356559   \n",
      "=================================================================\n",
      "Total params: 4,493,093\n",
      "Trainable params: 4,493,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "81f5eb9138cc4867805fad216a0d3782ab071d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "45584/45584 [==============================] - 122s 3ms/step - loss: 6.8409\n",
      "Epoch 2/2\n",
      "45584/45584 [==============================] - 120s 3ms/step - loss: 6.5243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4686fb9f60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2f7ad9dd26749b4b7fd1e38aa13cc100e3d8fdb3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 117s - loss: 6.3864\n",
      "Epoch 2/20\n",
      " - 118s - loss: 6.2434\n",
      "Epoch 3/20\n",
      " - 117s - loss: 6.0836\n",
      "Epoch 4/20\n",
      " - 117s - loss: 5.8921\n",
      "Epoch 5/20\n",
      " - 117s - loss: 5.6794\n",
      "Epoch 6/20\n",
      " - 117s - loss: 5.4415\n",
      "Epoch 7/20\n",
      " - 117s - loss: 5.1732\n",
      "Epoch 8/20\n",
      " - 117s - loss: 4.8994\n",
      "Epoch 9/20\n",
      " - 117s - loss: 4.6182\n",
      "Epoch 10/20\n",
      " - 117s - loss: 4.3345\n",
      "Epoch 11/20\n",
      " - 117s - loss: 4.0764\n",
      "Epoch 12/20\n",
      " - 117s - loss: 3.8362\n",
      "Epoch 13/20\n",
      " - 117s - loss: 3.6269\n",
      "Epoch 14/20\n",
      " - 118s - loss: 3.4266\n",
      "Epoch 15/20\n",
      " - 117s - loss: 3.2586\n",
      "Epoch 16/20\n",
      " - 117s - loss: 3.0961\n",
      "Epoch 17/20\n",
      " - 117s - loss: 2.9527\n",
      "Epoch 18/20\n",
      " - 117s - loss: 2.8220\n",
      "Epoch 19/20\n",
      " - 118s - loss: 2.7116\n",
      "Epoch 20/20\n",
      " - 117s - loss: 2.6061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f463e4147b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "8cf6f94e09e0c1bbe2ab875d5ad5ad04fa273f17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f463e46e9e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78ed237f742213954216c650ea7ecc8025ba3fcd"
   },
   "source": [
    "## 5. Generating the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "14a8a83c14e9a583b85ee8bb26fc8b9dc450877c"
   },
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b200a4e3ce1feff5335badcd51449052dac14326",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  Julius Heavy Theres As Is A King Saint Question That A Night Or A Struck Of A Ways A Bishop Of\n",
      "2.  Thou Art The King Of Honour And Would Do Not My Lord Of The Jest And The Ant Of Him By\n",
      "3.  King Is Grief In Buckram Here And So My Friends I Am No Talbots Am I Heard Now No A Man As\n",
      "4.  Death Of The Duchess Blood Let Of Our Coats Or Take It Thunders And Lightens Terribly Then The Spirit Riseth A Man\n",
      "5.  The Princess Of Deep Prophecy Did Hath Bought With Me That A World Of A Loss And A Gallows Enter Enter Bastard\n",
      "6.  Thanos My Lord Of Winchester I Know Your Mind To You To Stay Of All If A Fight And A True\n"
     ]
    }
   ],
   "source": [
    "print (\"1. \",generate_text(\"Julius\", 20, model, max_sequence_len))\n",
    "print (\"2. \",generate_text(\"Thou\", 20, model, max_sequence_len))\n",
    "print (\"3. \",generate_text(\"King is\", 20, model, max_sequence_len))\n",
    "print (\"4. \",generate_text(\"Death of\", 20, model, max_sequence_len))\n",
    "print (\"5. \",generate_text(\"The Princess\", 20, model, max_sequence_len))\n",
    "print (\"6. \",generate_text(\"Thanos\", 20, model, max_sequence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f9893f9d0a83b81d3c17c67fd4db98a6dc19ec60"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
